Author Response Please find the attached file.
Author Response File: Author Response.pdf
Author Response Please find the attached file.
Author Response File: Author Response.pdf
Author Response Attached please find the Q&A file.
Author Response File: Author Response.pdf
The manuscript is well written, well organized, and clear.
The results show a higher performance of the proposed computation of inverse transforms.
Additions also affect complexity.
Please add information on the number of additions for different transform types and sizes in original and proposed variants.
The authors should accurately address the below comments.
Keywords: We suggest that the authors should replace keywords such as “video coding” and “transform” because these keywords are already found in the article title.
It is better that they replace them with other keywords to increase the reach of the manuscript.
Introduction Section: The authors should add the main contributions briefly at the end of the introduction.
Methodology Section: It should be structured, sub-headings should be added to facilitate tracking and understanding.
Discussion Section: The authors should add a section where they discuss comparing their results with those of existing research.
Also, they should clarify the limitations of the proposed method.
There is a lot of recent research out there that can be used for comparison.
As this discussion and comparison can clarify the fairness and rationality of the results of the proposed method.
Conclusions: Future directions should be added to the conclusion section.
Figures and Tables: All figures and tables are shown before they are used in the text.
References List: The list of references is recent, and all references are related to the research topic but it is not sufficient for this study.
The names of the researchers must follow the style of the journal format.
The double quotation should be omitted from the research titles in the list of references.
Some search names in the reference list begin an uppercase letter for each word (such as [4], [5] ...
etc.)
and others use only an uppercase letter in the first word (such as [2], [9] … etc.
), authors should standardize style.
All journal names should be italic.
Some references do not contain enough information such as [16], [18] … etc.
Some links do not work in the reference list like [22] … etc.
The list of references requires an extensive check.
English Writing: This article requires extensive proofreading.
Authors should check the entire article to remove all extensive mistakes (grammatical and typos) and to improve English writing quality.
The authors should accurately address the below comments.
Introduction Section: This comment still requires a response.
The authors should add the main contributions briefly at the end of the introduction.
Discussion Section: The authors did not respond accurately to this comment.
The authors should add a section where they discuss comparing their results with those of existing research.
Also, they should clarify the limitations of the proposed method.
Figures and Tables: All figures and tables are shown before they are used in the text.
Inverse Transform Using Linearity Hyeonju Song, and Yung-Lyul Lee Digital Media System Laboratory, Department of Computer Engineering, Sejong University, Seoul, Korea.
<Reviewer 1> “The manuscript is well written, well organized, and clear.
The results show a higher performance of the proposed computation of inverse transforms.” We would like to thank the reviewer for the thorough review and very helpful comments.
The revised manuscript was reviewed and substantially modified by a native speaker.
According to the reviewer’s comment, we included two new Tables, Table 3 and Table 4, so that the table indices were changed accordingly.
In answer to the specific comments: Comment) Additions also affect complexity.
Please add information on the number of additions for different transform types and sizes in original and proposed variants.
Answer) According to reviewer’s comment, we added Equation (14), and Tables 3 and 4 on the number of additions for the VVC inverse transforms.
We included the following sentence and Equation (14) on page 4: “For an (n×m) transform block which has N non-zero coefficients, the total number of additions in the proposed inverse transform using linearity is computed in Equation (14), even though Equation (14) is not used in the proposed method: We included the following Table 3 and 4 and sentences on page 6: Table 3.
The number of additions when the horizontal and vertical transforms are both DCT-II in the VTM-8.2.
Width (m) 1 2 4 8 16 32 64 Height (n) 1 N/A 2 8 28 100 372 802 2 2 8 24 72 232 808 1668 4 8 24 64 176 528 1744 3464 8 28 72 176 448 1248 3872 7312 16 100 232 528 1248 3200 9152 16032 32 372 808 1744 3872 9152 23808 37568 (N −1) × (n × m) (14) 64 802 1732 3720 8208 19232 49472 76992 Table 4.
The number of additions when the horizontal and vertical transforms are combination of DST-VII and DCT-VIII in the VTM-8.2.
Width (m) 4 8 16 32 Height (n) 4 88 344 796 3048 8 344 1024 2264 6768 16 796 2264 4960 13968 32 3224 7792 16448 34464 “As a reference, Table 3 lists the number of additions computed in the VTM-8.2 source code in each (n  m) block size when the horizontal kernel and vertical transforms are both DCT-II.
Table 4 presents the number of additions computed in the VTM-8.2 source code in each (n  m) block size when the horizontal and vertical transforms are a combination of DST-VII and DCT-VIII.
It can be easily computed by Equation (14) that the number of additions of the proposed method is smaller for all block sizes than those in VTM-8.2.”
Inverse Transform Using Linearity Hyeonju Song*, and Yung-Lyul Lee* *Digital Media System Laboratory, Department of Computer Engineering, Sejong University, Seoul, Korea.
<Reviewer 2> “The authors should accurately address the below comments.” We would like to thank the reviewer for the thorough review and very helpful comments.
The revised manuscript was reviewed and substantially modified by a native speaker.
According to a reviewer’s comment, we included two new Tables, Table 3 and Table 4, so that the table indices were changed accordingly.
In answer to the specific comments: Comment) Keywords : We suggest that the authors should replace keywords such as “video coding” and “transform” because these keywords are already found in the article title.
It is better that they replace them with other keywords to increase the reach of the manuscript.
Answer) According to the reviewer’s comment, we modified and added some keywords as follows: We replaced “Keywords: VVC; HEVC; video coding; transform; computational complexity” With “Keywords: VVC (Versatile Video Coding), HEVC (High Efficiency Video Coding, Linear Inverse Transform, computational complexity, DCT (Discrete Cosine Transform), Discrete Sine Transform (DST), BD-rate” Comment) Introduction: The authors should add the main contribution s briefly at the end of the introduction.
Answer) According to the reviewer's comments, we updated the last paragraph of Section 1 as follows: We replaced “Section 2 presents a proposed inverse transform using linearity to reduce the computational complexity.” With “In Section 2.1, we introduce the transforms used in VVC.
And we propose a fast inverse transform using linearity to reduce the computational complexity in Section 2.2.” Comment) Methodology Section: It should be structured, sub-headings should be added to facilitate tracking and understanding.
Answer) According to the reviewer’s comment, we divided Section 2 as follows: 2.
VVC Transforms and Proposed Method 2.1.
Introduction to DCT-II, DST-VII, and DCT-VIII 2.2.
Propose Fast Inverse Transform Using Linearity Comment) The authors should add a section where they discuss comparing their results with those of existing research.
Also, they should clarify the limitations of the proposed method.
There is a lot of recent research out there that can be used for comparison.
As this discussion and comparison can clarify the fairness and rationality of the results of the proposed method.
Answer) According to the reviewer’s comment, we included the following sentence in the end of 3.
Experimental Results section on page 11: ~~ “Fast encoding methods only in the encoder side were proposed to reduce the encoding complexity of VVC but all the fast encoding methods increased the BD-rates [29][30][31] in terms of the bit-rate reduction so that the proposed inverse transform using linearity in the decoder side differs from those approaches in that it keeps the BD-rate in VVC while reducing the decoding complexity.
If the proposed inverse transform is applied to the VVC standard, the inverse transform of the VVC standard should be changed to include the proposed method.
Therefore, the proposed method can be considered in the next-generation video coding standards because it reduces the decoding complexity while the BD-rate is maintained.” ~~ And three new references [29],[30], and [31] in Reference section were included.
Comment) Conclusions: Future directions should be added to the Conclusion Section.
Answer) According to the reviewer’s comment, we added the future directions in the conclusion section as follows: “The proposed method can be considered in the next-generation video coding standards because it reduces the decoding complexity while the BD-rate is maintained.” Comment) Figures and Tables: All figures and tables are shown before they are used in the text Answer) Only Table 6 was shown before it was used.
So, we removed the word Table 6 in the following sentence: ~~.
“Table 3 lists the percentages of horizontal and vertical transforms in VTM-8.2 for all test sequences in Table 6 which are to be explained in Section 3—at each Quantization …” ~~~ Comment) The list of references is recent, and all references are related to the research topic but it is not sufficient for this study.
The names of the researchers must follow the style of the journal format.
The double quotation should be omitted from the research titles in the list of references.
Some search names in the reference list begin an uppercase letter for each word (such as [4], [5] ...
etc.)
and others use only an uppercase letter in the first word (such as [2], [9] … etc.
), authors should standardize style.
All journal names should be italic.
Some references do not contain enough information such as [16], [18] … etc.
Some links do not work in the reference list like [22] … etc.
The list of references requires an extensive check Answer) Thank you for pointing out our mistake.
According to the reviewer’s comment, we completely updated the list of references as follows: 1.
Advanced Video Coding (AVC), Standard ITU-T Recommendation H.264 and ISO/IEC 14496-10, May 2003.
2.
Wiegand, T.; Sullivan, G. J.; Bjontegaard, G.; Luthra, A. Overview of the H.264/AVC Video Coding Standard, In IEEE Transactions on Circuits and Systems for Video Technology, 2003, vol.
13, pp.
560-576, doi: 10.1109/TCSVT.2003.815165.. 3.
High Efficient Video Coding (HEVC), Standard ITU-T Recommendation H.265 and ISO/IEC 23008-2, Apr.
2013.
4.
Sullivan, G. J.; Ohm, J.; Han, W.; Wiegand, T. Overview of the High Efficiency Video Coding (HEVC) Standard, In IEEE Transactions on Circuits and Systems for Video Technology, 2012, vol.
22, pp.
1649-1668, doi: 10.1109/TCSVT.2012.2221191.
5.
Bross, B.; Chen, J.; Liu, S.; Wang, Y.-K. Versatile Video Coding (Draft 10).
In Proceedings of the 19th Meeting Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, Teleconference (Online), 22 June-1 July 2020; 6.
Bross, B.; Wang, Y.-K; Ye, Y,; Liu, S.; Sullivan, G. J.; Ohm, J. Overview of the Versatile Video Coding (VVC) Standard and its Applications, In IEEE Transactions on Circuits and Systems for Video Technology, 2021, vol.
31, pp.
3736-3764, doi: 10.1109/TCSVT.2021.3101953 7.
Karhunen, K. Über Lineare Methoden in der Wahrscheinlichkeitsrechnung, Soumalainen Tiedeakatemia, 1947; pp.
1-79.
8.
Ahmed, N.; Natarajan, T.; Rao, K. R. Discrete Cosine Transform, In IEEE Transactions on Computers, 1974, vol.
C-23, pp.
90-93, doi: 10.1109/T-C.1974.223784.
9.
Rose, K.; Heiman, A.; Dinstein, I. DCT/DST Alternate-Transform Image Coding, In IEEE Transactions on Communications, 1990, vol.
38, pp.
94-101, doi: 10.1109/26.46533.
10.
Zhao, X.; Chen, J.; Karczewicz, M.; Zhang, L.; Li, X.; Chien, W. -J.
Enhanced Multiple Transform for Video Coding, 2016 Data Compression Conference (DCC), 2016, pp.
73-82, doi: 10.1109/DCC.2016.9.
11.
Han, J.; Saxena, A.; Melkote, V.; Rose, K. Jointly Optimized Spatial Prediction and Block Transform for Video and Image Coding, In IEEE Transactions on Image Processing, 2012, vol.
21, pp.
1874-1884, doi: 10.1109/TIP.2011.2169976.
12.
Budagavi, M.; Fuldseth, A.; Bjøntegaard, G.; Sze, V.; Sadafale, M. Core Transform Design in the High Efficiency Video Coding (HEVC) Standard, In IEEE Journal of Selected Topics in Signal Processing, 2013, vol.
7, pp.
1029-1041, doi: 10.1109/JSTSP.2013.2270429.
13.
Zhao, X.; Chen, J.; Karczewicz, M.; Said, A.; Seregin, V. Joint Separable and Non-Separable Transforms for Next-Generation Video Coding, In IEEE Transactions on Image Processing, 2018, vol.
27, no.
5, pp.
2514-2525, doi: 10.1109/TIP.2018.2802202.
14.
Zhao, X.; Chen, J.; Said, A.; Seregin, V.; Egilmez, H. E.; Karczewicz, M. NSST: Non-separable secondary transforms for next generation video coding, 2016 Picture Coding Symposium (PCS), 2016, pp.
1-5, doi: 10.1109/PCS.2016.7906344.
15.
Zhao, X.; Kim, S,-H,; Zhao, Y.; Eglimez, H.; Koo, M.; Liu, S.; Lainema, J.; Karczewicz, M. Transform Coding in the VVC Standard, In IEEE Transactions on Circuits and Systems for Video Technology, 2021, vol.
31, no.
10, pp.
3878-3890, doi: 10.1109/TCSVT.2021.3087706.
16.
Koo, M.; Salehifar, M.; Lim, J.; Kim, S. -H. CE6-Related: 32 Point MTS Based on Skipping High Frequency Coefficients.
In Proceedings of the 13th Meeting Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, Marrakech, Morocco, 9-18 January 2019; 17.
Koo, M.; Salehifar, M.; Lim, J.; Kim, S.-H. Low Frequency Non-Separable Transform (LFNST), 2019 Picture Coding Symposium (PCS), 2019, pp.
1-5, doi: 10.1109/PCS48520.2019.8954507.
18.
Koo, M.; Salehifar, M.; Lim, J.; Kim, S. -H. CE6: Reduced Secondary Transform (RST) (CE6-3.1).
In Proceedings of the 14th Meeting Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, Geneva, Swiss, 19-27 March 2019; 19.
Chiang, M.-S.; Hsu, C.
–W.
; Huang, U.
-W.; Lei, S. –M.
CE6-related: Simplifications for LFNST, document- O0292, In Proceedings of the 15th Meeting Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, Gothenburg, Sweden, 3-12 July 2019; 20.
Siekmann, M.; Schwarz, H.; Marpe, D.; Wiegand, T. CE6-2.1: Simplification of Low Frequency Non-Separable Transform, document-O0094, In Proceedings of the 15th Meeting Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, Gothenburg, Sweden, 3-12 July 2019; 21.
Schwarz, H.; Coban, M.; Karczewicz, M.; Chuang, T.-D.; Bossen, F.; Alshin, A.; Lainema, J.; Helmrich, C.; Wiegand, T. Quantization and Entropy Coding in the Versatile Video Coding (VVC) Standard, In IEEE Transactions on Circuits and Systems for Video Technology, 2021, vol.
31, no.
10, pp.
3891-3906, doi: 10.1109/TCSVT.2021.3072202.
22.
VVC Test Model (VTM-8.2) Reference Software.
Available online: https://vcgit.hhi.fraunhofer.de/jvet/VVCSoftware_VTM/-/tree/VTM-8.2 (accessed on 6 September 2021) 23.
Hung, C. -Y.; Landman, P. Compact inverse discrete cosine transform circuit for MPEG video decoding, In 1997 IEEE Workshop on Signal Processing Systems.
SiPS 97 Design and Implementation formerly VLSI Signal Processing, 1997, pp.
364-373, doi: 10.1109/SIPS.1997.626269.
24.
Zhao, X.; Li, X.; Luo, Y.; Liu, S. CE6: Fast DST-7/DCT-8 With Dual Implementation Support (Test 6.2.3), document-M0497, In Proceedings of the 13th Meeting Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, Marrakech, Morocco, 9-18 January 2019; 25.
Zhang, Z.; Zhao, X.; Li, X.; Li, L.; Luo, Y.; Liu, S.; Li, Z.
Fast DST-VII/DCT-VIII With Dual Implementation Support for Versatile Video Coding, In IEEE Transactions on Circuits and Systems for Video Technology, 2021, vol.
31, pp.
355-371, doi: 10.1109/TCSVT.2020.2977118.
26.
Bossen, F.; Boyce, J.; Suehring, K.; Li, X.; Seregin, V. JVET Common Test Conditions and Software Reference Configurations for SDR Video, document JVET-T2010, In Proceedings of the 20th Meeting Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, Teleconference (Online), 7-16 October 2020; 27.
Bjontegaard, G. Calculation of Average PSNR Differences Between Rd-Curves, Austin, TX, USA, pp.
10-18, Apr.
2001, Available online : http://wftp3.itu.int/av-arch/video-site/0104_Aus/.
(accessed on 3 January 2022) 28.
Bjontegaard, G. Improvement of Bd-PSNR Model, Berlin, Germany, pp.
10-18, Jul.
2008, Available online : https://www.itu.int/wftp3/av-arch/video-site/0807_Ber/.
(accessed on 3 January 2022) 29.
Dong, X.; Shen, L.; Yu, M.; Yang, H. Fast Intra Mode Decision Algorithm for Versatile Video Coding.
IEEE Transactions on Multimedia, 2022, vol.
24, pp.
400-414, doi: 10.1109/TMM.2021.3052348.
30.
Yang, H.; Shen, L.; Dong, X.; Ding, Q.; An, P.; Jiang, G. Low-Complexity CTU Partition Structure Decision and Fast Intra Mode Decision for Versatile Video Coding.
IEEE Transactions on Circuits and Systems for Video Technology, 2020, vol.
30, no.
6, pp.
1668-1682 doi: 10.1109/TCSVT.2019.2904198.
31.
Park, S. -H.; Kang, J.
-W. Fast Affine Motion Estimation for Versatile Video Coding (VVC) Encoding.
IEEE Access, 2019, vol.
7, pp.
158075-158084, doi: 10.1109/ACCESS.2019.2950388.
Comment) This article requires extensive proofreading.
Authors should check the entire article to remove all extensive mistakes (grammatical and typos) and to improve English writing quality.
Answer) According to the reviewer’s comment, the revised manuscript was reviewed and substantially modified by an English native speaker.
Inverse Transform Using Linearity Hyeonju Song*, and Yung-Lyul Lee* *Digital Media System Laboratory, Department of Computer Engineering, Sejong University, Seoul, Korea.
<Reviewer 2> The authors should accurately address the below comments.
• Introduction Section: This comment still requires a response.
The authors should add the main contributions briefly at the end of the introduction.
• Discussion Section: The authors did not respond accurately to this comment.
The authors should add a section where they discuss comparing their results with those of existing research.
Also, they should clarify the limitations of the proposed method.
• Figures and Tables: All figures and tables are shown before they are used in the text.
We would like to thank the reviewer for the thorough review and very helpful comments.
The revised manuscript was reviewed and substantially modified by a native speaker.
Ref [31] was removed because the paper was nothing to do with the proposed manuscript.
In answer to the specific comments: Comment 1) Introduction Section: This comment still requires a response.
The authors should add the main contributions briefly at the end of the introduction.
Answer 1) According to reviewer’s comment, we the following sentences at the end of the Introduction.
“In this paper, we analyze the number of multiplications of the existing fast transform methods in the VVC standard, and we propose a new fast inverse transform using the number of non-zero coefficients based on linearity to reduce the number of multiplications.” Comment 2) Discussion Section: The authors did not respond accurately to this comment.
The authors should add a section where they discuss comparing their results with those of existing research.
Also, they should clarify the limitations of the proposed method.
Answer 2) According to reviewer’s comment, we added Discussion Section.
4.
Discussion The previously proposed fast methods were mainly addressed to reduce complexity in the video encoder with the BD-rate loss.
In [29], a fast intra mode decision algorithm was proposed and the result showed the encoding time savings of 51%~53% with BD-rate loss of 0.93%~1.08%.
A low-complexity CTU (Coding Tree Unit) partition structure decision and fast intra mode decision were proposed in [30] and showed the average encoding time saving of 63% with the BD-rate loss of 1.93%.
The fast encoders for video coding reduce only the encoder complexity but the BD-rates were always increased without decreasing the decoder complexity.
However, the proposed fast inverse transform is different from the fast encoders in that it reduces the complexity in both the encoder and decoder while maintaining the BD- rate of the VVC standard.
In the RA configuration, the proposed method reduces the average encoding and decoding times by approximately (4, 10) %, respectively, while maintaining average BD-rates.
If the proposed inverse transform using the number of non-zero coefficients is applied to the VVC standard, the inverse transform of the VVC standard should be changed to include the proposed method.
This fact can be demerit.
However, the proposed method can be considered in the next-generation video coding standards because it achieves decoding run-time saving, while maintaining average BD-rate.
In addition to that, the proposed method is more effective in high QP value than in low QP value, because the higher the QP value is, the fewer no-zero coefficients there are.
Comment 3) Figures and Tables: All figures and tables are shown before they are used in the text.
Answer 3) We cannot find them.